# Email-Sender-Classification

## Dataset Description:
The Enron Corpus dataset is a large database of over 500,000 emails generated by around 150 employees of the Enron Corporation. The data 
consisted of inconsistencies and so we used the Enron dataset version compiled by William W. Cohen, in which large number of repeated
messages were removed. The overall size of this version is 1.77 GB. The data consists of emails presented in the form of text files in 
different folders.

Download dataset from https://www.cs.cmu.edu/~enron/

## Data Extraction
Data Extraction plays an important part in the processing step as we need to convert the unstructured data into structured format for ease
in processing and generation of new features. Data Extraction plays an important part in the processing step as we need to convert the 
unstructured data into structured format for ease in processing and generation of new features. We extracted the content of text files and
made a csv file which consisted of folder location of email and email details. Then, we created a csv which separated all email content 
into various columns based on their tag (X-From, X-To,bcc, cc etc).

Run <b>Data_Extraction.ipynb</b> to extract from raw text files.

## Data Preprocessing
Email content have a lot of inconsistencies which include email chains. Email chains create a lot of repetitive data. Removal of these can lead to content of the email being empty if the user has only forwarded the email. We first removed the email chains from the content. Since our feature extraction is based on content of the email, we also removed all emails that have no content.


Code for data preprocessing is in <b>preprocessing.py</b>

Training on 150 employees is too complicated and thus we have limited to 10 employees. The method applied to choose these authors is based on who sent the most number of emails. We had approximately 140,000 emails for top 10 senders.

## Feature Generation
The sender's content plays an important role in identifying the writing style/uniqueness of the content. The most important thing was to generate relevant features from the content. The features we generated belong to the following 7 Categories:
1) Sentence Based Features
2) Paragraph Based Features
3) Character Based Features
4) Word Based Features
5) Punctuation Based Features
6) Syntactic Based Features
7) Semantic Based Features

Code for generation of the above categories of features are present in the <b>Feature Generation Folder.</b>

## Machine Learning Techniques
The machine learning techniques that we have used for our implementation are as follows:
1) SVM
2) KNN
3) Random Forest Classifier
4) Hierarchical Attention Network with stylo features (Proposed Method)

Run the <b>Enron_main.ipynb</b> file for the first three machine learning algorithms.<br>
Run the <b>HAN.ipynb</b> file for Hierarchical Bi-LSTM algorithm.

## Results

<b> Precision, Recall and F1 Scores of ML Algorithms </b>

![alt text](https://github.com/kdave97/Email-Sender-Classification/blob/master/Results/Scores.png)

<b> Acccuracy of different techniques </b>

![alt text](https://github.com/kdave97/Email-Sender-Classification/blob/master/Results/accuracy.png)

<b> Confusion Matrix for HAN </b>

![alt text](https://github.com/kdave97/Email-Sender-Classification/blob/master/Results/HAN_Confusion_Matrix.png)

<b> Sample vs Accuracy </b>

![alt text](https://github.com/kdave97/Email-Sender-Classification/blob/master/Results/sample_accuracy.png)






